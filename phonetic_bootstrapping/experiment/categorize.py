__author__ = 'GCassani'

"""Function to categorize test items in terms of lexical categories using phonological information"""

import json
import operator
import numpy as np
from time import strftime
from collections import defaultdict
from corpus.encode.item import encode_item
from phonetic_bootstrapping.pos_tagging.assign import pick_pos
from phonetic_bootstrapping.pos_tagging.tags import get_frequency_and_activation_for_each_pos
from phonetic_bootstrapping.pos_tagging.helpers import compute_outcomes_activations


def categorize(test_items, logfile, weights_matrix, cues2ids, outcomes2ids, method='freq', evaluation='count',
               stats=False, k=100, flush=0, uni_phones=True, di_phones=False, tri_phones=False, syllable=False,
               stress_marker=False):

    """
    :param test_items:      an iterable containing strings. Each string is the phonological form of a word together
                            with its PoS tag, separated by a vertical bar ('|')
    :param logfile:         the path to a .txt file, where the function prints information about the processes it runs
                            and their outcome
    :param weights_matrix:  a NumPy array containing the matrix of cue-outcome associations estimated via the ndl
                            module; rows represent cues, columns represent outcomes.
    :param cues2ids:        a Python dictionary mapping cues to row indices in the weight matrix
    :param outcomes2ids:    a Python dictionary mapping outcomes to column indices in the weight matrix
    :param method:          a string indicating the way in which the function looks at top active outcomes; two
                            options are available:
                            - 'freq' makes the function compute the distribution of PoS tags over the k top active
                                nodes (see the explanation of the parameter k) and rank PoS tags according to their
                                frequency among the top active cues
                            - 'sum' makes the function compute the sum of activation from all outcomes belonging to
                                a given PoS tag within the k top active outcomes given the input cues, and rank PoS
                                tags according to their total activation among the top active cues
    :param evaluation:      a string indicating how to compare baseline activations to item-triggered ones; two
                            options are available:
                            - 'count', simply tag the test item with the PoS tag that either was more frequent or
                                had highest summed activation within the top active outcomes; frequency or
                                activation are returned and can be correlated to reaction times
                            - 'distr', compare the frequency counts or summed activations generated by a specific
                                test item to the frequency counts or summed activations at baseline and tag the test
                                item with the PoS tag receiving highest support by the change in the distribution of
                                frequencies or summed activations (a statistic is returned, Chi-squared for
                                frequency distributions and t-test for summed activations, whose value can be
                                correlated to reaction times)
    :param stats:           if True, makes the function assign a PoS tag to a test item based on the result of a
                            statistical test (Chi-squared for frequencies, t-test for activations): with the
                            Chi-squared, the PoS tag is chosen whose Pearson standardised residual is highest for the
                            item-triggered frequency distribution; with the t-test, the PoS tag is chosen that...
                            if False, the PoS tag with the highest positive difference between item-triggered and
                            baseline frequency/activation is chosen
                            CAVEAT: this parameter only makes sense if the 'distr' option is chosen for the 'evaluation'
                                        parameter
    :param k:               an integer specifying how many elements to consider from the baseline activations and
                            the activations triggered by a specific test item. By default, the top 100 outcomes are
                            considered, and compared according to the chosen combination of method and eval
    :param flush:           specify whether (and how many) top active outcome at baseline to flush away from
                            subsequent computations. It may be the case that whatever the input cues, the same high
                            frequency outcomes come out as being the most active. It may then make sense to not
                            consider them when evaluating the distribution of lexical categories over the most
                            active outcomes given an input item
    :param uni_phones:      a boolean indicating whether single phonemes are to be considered while encoding input
                            utterances
    :param di_phones:       a boolean indicating whether sequences of two phonemes are to be considered while
                            encoding input utterances
    :param tri_phones:      a boolean indicating whether sequences of three phonemes are to be considered while
                            encoding input utterances
    :param syllable:        a boolean indicating whether syllables are to be considered while encoding input
                            utterances
    :param stress_marker:   a boolean indicating whether stress markers from the input phonological representation need
                            to be preserved or can be discarded
    :return f1:             the proportion of items from the input iterable that could be categorized correctly - the
                            PoS tag of the words receiving highest activation given the phonetic cues in each test item
                            matched the PoS tag attached to the test item itself
    :return h:              the normalized entropy of the distribution of PoS tags chosen by the model when tagging test
                            items. If a model always chooses the same PoS tag, the entropy will be minimal; ideally, a
                            good model doesn't behave like a majority baseline model, even though this might result in
                            high accuracy scores
    :return pos:            the PoS tag that is applied most frequently by a model. Useful to spot anomalous
                            over-extension of a PoS tag
    :return freq:           the frequency with which the most frequent PoS tag applied by the model is actually applied
    """

    if type(weights_matrix) is not dict:
        ValueError("Unrecognized input structure: .")

    to_filter = set()
    baseline_activations = compute_outcomes_activations(cues2ids.keys(), weights_matrix, cues2ids,
                                                        outcomes2ids, to_filter)
    sorted_baseline_activations = sorted(baseline_activations.items(), key=operator.itemgetter(1), reverse=True)

    # if top active outcomes at baseline need to be flushed away, store flushed outcomes in a set and store the other
    # outcomes in a list of tuples
    if flush:
        to_filter = {outcome[0] for outcome in sorted_baseline_activations[:flush]}
        sorted_baseline_activations = sorted_baseline_activations[flush:]

    # compute baseline frequency distribution over PoS tags and PoS summed activation over the k most active outcomes
    # given all input cues at once
    pos_freq_baseline, pos_act_baseline = get_frequency_and_activation_for_each_pos(sorted_baseline_activations[:k])

    hits = 0
    total = 0
    total_items = len(test_items)
    check_points = {int(np.floor(total_items / 100 * n)): n for n in np.linspace(5, 100, 20)}

    log_dict = defaultdict(dict)

    tags = set()
    for item in test_items:

        tags.add(item.split("|")[1])

        if not isinstance(item, str):
            ValueError("The input items must consist of strings: check your input file!")

        # split the test token from its Part-of-Speech and encode it in nphones
        word, target_pos = item.split('|')
        word = '+' + word + '+'
        nphones = encode_item(word, uni_phones=uni_phones, di_phones=di_phones,
                              tri_phones=tri_phones, syllable=syllable, stress_marker=stress_marker)

        # compute outcome activations given the phonetic cues in the test item, sort the outcomes by outcome activation
        # value and pick the top k
        outcome_activations = compute_outcomes_activations(nphones, weights_matrix, cues2ids, outcomes2ids, to_filter)
        sorted_outcome_activations = sorted(outcome_activations.items(), key=operator.itemgetter(1), reverse=True)[:k]

        if sorted_outcome_activations[0][1] == 0:
            # if the activation of the first item is 0 it means that no phonetic cue from the test item was ever
            # encountered in the corpus, and it is thus impossible to estimate which are most active outcomes given
            # the phonetic cues of which the test item consists
            top_pos, value, n_freq, v_freq, n_act, v_act = ('-', 0, 0, 0, 0, 0)

        else:
            # compute frequency distribution over PoS tags and PoS summed activation over the k most active outcomes
            # given the test item, then get how many verbs and nouns there were among to k top active outcomes
            pos_freq_item, pos_act_item = get_frequency_and_activation_for_each_pos(sorted_outcome_activations)
            n_freq = pos_freq_item['N']
            v_freq = pos_freq_item['V']
            n_act = pos_act_item['N']
            v_act = pos_act_item['V']

            # get the most likely PoS tag for the test item given the k top active outcomes
            top_pos, value = pick_pos(pos_freq_item, pos_act_item, pos_freq_baseline, pos_act_baseline,
                                      evaluation=evaluation, method=method, stats=stats)

        # print the test item (with the correct PoS tag), the PoS tag assigned by the model, the statistic computed to
        # assign the chosen PoS (frequency/activation count or difference) and the k top active nodes given the test
        # item
        log_dict[item] = {'predicted': top_pos,
                          'value': value,
                          'n_freq': n_freq,
                          'v_freq': v_freq,
                          'n_act': n_act,
                          'v_act': v_act,
                          'items': {k: v for (k, v) in sorted_outcome_activations}}

        # compare the predicted and true PoS tag and increment the count of hits if they match
        if top_pos == target_pos:
            hits += 1

        total += 1

        if total in check_points:
            print(strftime("%Y-%m-%d %H:%M:%S") + ": %d%% of the test items have been processed."
                  % check_points[total])

    json.dump(log_dict, open(logfile, 'w'))

    return log_dict
